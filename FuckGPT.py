# requires: openai
# developer: @weeldag                                    
import openai
from .. import loader, utils
from telethon.tl.types import Message


@loader.tds
class FuckGPTMod(loader.Module):
    """Module for interacting with GPT different prompts"""
    strings = {
        "name": "FuckGPT",
        "wait": "<emoji document_id=5443038326535759644>üí¨</emoji><b> GPT is generating answer, wait</b>",
        "wait_aim": "<emoji document_id=5443038326535759644>üí¨</emoji><b> AIM is generating answer, wait</b>",
        "quest_k": "\n\n\n<emoji document_id=5260341314095947411>üëÄ</emoji><b> Your question to Kelvin was:</b> {args}",
        "quest": "\n\n\n<emoji document_id=5260341314095947411>üëÄ</emoji><b> Your question to GPT was:</b> {args}",
        "quest_aim": "\n\n\n<emoji document_id=5260341314095947411>üëÄ</emoji><b> Your question to AIM was:</b> {args}",
        "args_err": "<emoji document_id=5260342697075416641>‚ùå</emoji><b> You didn't ask a question GPT</b>",
        "conf_err": "<emoji document_id=5260342697075416641>‚ùå</emoji><b> You didn't provide an api key. Specify it in .config FuckGPT</b>",
        "limit_err": "<emoji document_id=5260342697075416641>‚ùå</emoji><b> The limit of requests has been reached. Repeat the question in 20 seconds</b>",
    }
    strings_ru = {
        "wait": "<emoji document_id=5443038326535759644>üí¨</emoji><b> GPT –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –æ—Ç–≤–µ—Ç, –ø–æ–¥–æ–∂–¥–∏—Ç–µ</b>",
        "wait_aim": "<emoji document_id=5443038326535759644>üí¨</emoji><b> AIM –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –æ—Ç–≤–µ—Ç, –ø–æ–¥–æ–∂–¥–∏—Ç–µ</b>",
        "quest_k": "\n\n\n<emoji document_id=5260341314095947411>üëÄ</emoji><b> –í–∞—à –≤–æ–ø—Ä–æ—Å –∫ –ö–µ–ª—å–≤–∏–Ω—É –±—ã–ª:</b> {args}",
        "quest": "\n\n\n<emoji document_id=5260341314095947411>üëÄ</emoji><b> –í–∞—à –≤–æ–ø—Ä–æ—Å GPT –±—ã–ª:</b> {args}",
        "quest_aim": "\n\n\n<emoji document_id=5260341314095947411>üëÄ</emoji><b> –í–∞—à –≤–æ–ø—Ä–æ—Å AIM –±—ã–ª:</b> {args}",
        "args_err": "<emoji document_id=5260342697075416641>‚ùå</emoji><b> –í—ã –Ω–µ –∑–∞–¥–∞–ª–∏ –≤–æ–ø—Ä–æ—Å GPT</b>",
        "conf_err": "<emoji document_id=5260342697075416641>‚ùå</emoji><b> –í—ã –Ω–µ —É–∫–∞–∑–∞–ª–∏ api key. –£–∫–∞–∂–∏—Ç–µ –µ–≥–æ –≤ .config FuckGPT</b>",
        "limit_err": "<emoji document_id=5260342697075416641>‚ùå</emoji><b> –î–æ—Å—Ç–∏–≥–Ω—É—Ç –ª–∏–º–∏—Ç –∑–∞–ø—Ä–æ—Å–æ–≤ –≤ –º–∏–Ω—É—Ç—É. –ü–æ–≤—Ç–æ—Ä–∏—Ç–µ –≤–æ–ø—Ä–æ—Å —á–µ—Ä–µ–∑ 20 —Å–µ–∫—É–Ω–¥</b>",
    }

    def __init__(self):
        self.config = loader.ModuleConfig(
            loader.ConfigValue(
                "api_key",
                None,
                lambda: "Api key for GPT",
                validator=loader.validators.Hidden(),
            ),
        )
        
        
    async def gptcmd(self, message: Message):
        """<question> - question for ChatGPT"""
        args = utils.get_args_raw(message)
        if not args:
            await utils.answer(message, self.strings("args_err"))
            return
        if self.config["api_key"] is None:
            await utils.answer(message, self.strings("conf_err"))
            return
        await utils.answer(message, self.strings("wait").format(args=args))
        openai.api_key = self.config["api_key"]
        try:
            completion = openai.ChatCompletion.create(
                model="gpt-3.5-turbo",
                messages=[
                    {"role": "user", "content": args}
                ]
            )
            response = completion.choices[0].message.content
            await utils.answer(message, f"<code>{response}</code>" + self.strings("quest").format(args=f"<code>{args}</code>"))
        except openai.error.RateLimitError:
            await utils.answer(message, self.strings("limit_err"))
       
    async def aimgptcmd(self, message: Message):
        """<question> - question for AIM"""
        args = utils.get_args_raw(message)
        if not args:
            await utils.answer(message, self.strings("args_err"))
            return
        if self.config["api_key"] is None:
            await utils.answer(message, self.strings("conf_err"))
            return
        await utils.answer(message, self.strings("wait_aim").format(args=args))
        openai.api_key = self.config["api_key"]
        try:
            completion = openai.ChatCompletion.create(
                model="gpt-3.5-turbo",
                messages=[
                    {"role": "user", "content": args}
                ]
            )
            response = completion.choices[0].message.content
            await utils.answer(message, f"<code>{response}</code>" + self.strings("quest").format(args=f"<code>{args}</code>"))
        except openai.error.RateLimitError:
            await utils.answer(message, self.strings("limit_err"))
        
    async def kgptcmd(self, message: Message):
        """<question> - question for Kelvin"""
        args = utils.get_args_raw(message)
        if not args:
            await utils.answer(message, self.strings("args_err"))
            return
        if self.config["api_key"] is None:
            await utils.answer(message, self.strings("conf_err"))
            return
        await utils.answer(message, self.strings("wait").format(args=args))
        openai.api_key = self.config["api_key"]
        try:
            completion = openai.ChatCompletion.create(
                model="gpt-3.5-turbo",
                messages=[
                    {"role": "user", "content": args}
                ]
            )
            response = completion.choices[0].message.content
            await utils.answer(message, f"<code>{response}</code>" + self.strings("quest").format(args=f"<code>{args}</code>"))
        except openai.error.RateLimitError:
            await utils.answer(message, self.strings("limit_err"))